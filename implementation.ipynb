{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQFvLvN77ygy"
      },
      "source": [
        "# SATR AI Co.,Ltd. Practical Test\n",
        "Current Date and Time (UTC): 2025-02-17 17:20:35\n",
        "Current User's Login: sesiii\n",
        "\n",
        "## Overview\n",
        "- Electricity demand forecasting using data from Kansai Electric Power (JP)\n",
        "- Target period: January 1, 2023, 00:00:00 – December 31, 2023, 23:00:00\n",
        "- Using weather data from 8 different cities and historical demand data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-CQOhxT70do",
        "outputId": "151568e6-5300-4bc6-a5fd-ccae310efbd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./experienced/experienced/your_env/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in ./experienced/experienced/your_env/lib/python3.12/site-packages (2.0.2)\n",
            "Requirement already satisfied: tensorflow in ./experienced/experienced/your_env/lib/python3.12/site-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in ./experienced/experienced/your_env/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in ./experienced/experienced/your_env/lib/python3.12/site-packages (3.10.0)\n",
            "Requirement already satisfied: jpholiday in ./experienced/experienced/your_env/lib/python3.12/site-packages (0.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in ./experienced/experienced/your_env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in ./experienced/experienced/your_env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in ./experienced/experienced/your_env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./experienced/experienced/your_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install pandas numpy tensorflow scikit-learn matplotlib jpholiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZKrpTP9H76SQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-17 23:57:45.234962: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-02-17 23:57:45.312901: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-02-17 23:57:45.388431: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739816865.451425   41652 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739816865.468967   41652 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-17 23:57:45.624990: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries and suppress warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import logging\n",
        "import pickle\n",
        "import absl.logging\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "# Suppress specific TensorFlow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "_Y3qW1uD78C_",
        "outputId": "b469a852-1627-4ae8-bd54-a1c0be7d8975"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Creates directories\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkdir -p data/electricity_demand data/Weather\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Creates directories\n",
        "!mkdir -p data/electricity_demand data/Weather\n",
        "\n",
        "print(\"Please upload demand.csv\")\n",
        "uploaded = files.upload()\n",
        "!mv demand.csv data/electricity_demand/\n",
        "\n",
        "# Upload weather data\n",
        "print(\"Please upload weather data files for all 8 cities\")\n",
        "uploaded = files.upload()\n",
        "for file in uploaded.keys():\n",
        "    if file.endswith('.csv'):\n",
        "        !mv \"$file\" data/Weather/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gS1vjlA79mN"
      },
      "source": [
        "## Model Development for Electricity Demand Forecasting\n",
        "\n",
        "### Method Selection and Justification\n",
        "- **Chosen Method**: LSTM (Long Short-Term Memory) Neural Network\n",
        "- **Justification**:\n",
        "  - Capable of capturing long-term dependencies in time series data\n",
        "  - Well-suited for sequential data with temporal patterns\n",
        "  - Can handle multiple input features (weather data from 8 cities)\n",
        "  - Effective at learning seasonal and daily patterns in electricity demand\n",
        "\n",
        "### Feature Engineering\n",
        "1. **Temporal Features**:\n",
        "   - Hour of day (captures daily patterns)\n",
        "   - Day of week (captures weekly patterns)\n",
        "   - Month (captures seasonal patterns)\n",
        "   - Weekend flag (captures weekend vs weekday differences)\n",
        "   - Holiday flag (using jpholiday library)\n",
        "\n",
        "2. **Weather Features**:\n",
        "   - Temperature (primary driver of electricity demand)\n",
        "   - Humidity (affects perceived temperature)\n",
        "   - Wind direction (encoded using cardinal directions)\n",
        "   - Precipitation and snowfall (impact on energy usage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HJjtY8Cm8Ads"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_weather_data(directory='data/Weather'):\n",
        "    \"\"\"Load and preprocess weather data from multiple cities\"\"\"\n",
        "    weather_files = glob.glob(os.path.join(directory, '*.csv'))\n",
        "    all_weather_data = {}\n",
        "\n",
        "    wind_mapping = {\n",
        "        '南': 0, '南南西': 1, '南南東': 2, '西': 3,\n",
        "        '北西': 4, '南西': 5, '西北西': 6, '北': 7,\n",
        "        '東': 8, '南東': 9, '北東': 10, '東北東': 11\n",
        "    }\n",
        "\n",
        "    for file in weather_files:\n",
        "        city_name = os.path.basename(file).replace('.csv', '')\n",
        "        df = pd.read_csv(file)\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        df.set_index('datetime', inplace=True)\n",
        "\n",
        "        df['wind_direction'] = df['wind_direction'].map(wind_mapping).fillna(0)\n",
        "\n",
        "        for col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "            df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "        # Add city prefix to columns\n",
        "        df.columns = [f'{city_name}_{col}' for col in df.columns]\n",
        "        all_weather_data[city_name] = df\n",
        "\n",
        "    # Combine all weather data\n",
        "    combined_weather = pd.concat(all_weather_data.values(), axis=1)\n",
        "    print(f\"Loaded weather data from {len(all_weather_data)} cities\")\n",
        "\n",
        "    # Handle any remaining NaN values\n",
        "    nan_cols = combined_weather.columns[combined_weather.isna().any()].tolist()\n",
        "    if nan_cols:\n",
        "        print(\"Columns with NaN values:\", nan_cols)\n",
        "        combined_weather = combined_weather.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    return combined_weather\n",
        "\n",
        "def prepare_data(demand_df, weather_df, sequence_length=24):\n",
        "    \"\"\"Prepare data for model training with additional checks\"\"\"\n",
        "    # Create time features\n",
        "    data = pd.DataFrame(index=demand_df.index)\n",
        "    data['demand'] = demand_df['actual_performance']\n",
        "    data['hour'] = data.index.hour\n",
        "    data['day_of_week'] = data.index.dayofweek\n",
        "    data['month'] = data.index.month\n",
        "    data['is_weekend'] = data.index.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "    # Add weather features\n",
        "    for col in weather_df.columns:\n",
        "        data[col] = weather_df[col]\n",
        "\n",
        "    # Handle any remaining missing values\n",
        "    if data.isna().any().any():\n",
        "        print(\"Handling remaining missing values if any....\")\n",
        "        data = data.fillna(data.mean())\n",
        "\n",
        "    # Print data statistics\n",
        "    print(\"\\nData Statistics:\")\n",
        "    print(data.describe())\n",
        "\n",
        "    # Handle infinite values\n",
        "    if np.isinf(data.values).any():\n",
        "        print(\"Replacing infinite values with mean values....\")\n",
        "        data = data.replace([np.inf, -np.inf], np.nan)\n",
        "        data = data.fillna(data.mean())\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(scaled_data) - sequence_length):\n",
        "        X.append(scaled_data[i:(i + sequence_length)])\n",
        "        y.append(scaled_data[i + sequence_length, 0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    if np.isnan(X).any():\n",
        "        print(\"Warning: NaN values found in X after preprocessing\")\n",
        "        X = np.nan_to_num(X, nan=0.0)\n",
        "    if np.isnan(y).any():\n",
        "        print(\"Warning: NaN values found in y after preprocessing\")\n",
        "        y = np.nan_to_num(y, nan=0.0)\n",
        "\n",
        "    return X, y, scaler, data.columns\n",
        "\n",
        "def create_model(input_shape):\n",
        "    \"\"\"Create an improved model architecture\"\"\"\n",
        "    model = Sequential([\n",
        "        tf.keras.Input(shape=input_shape),\n",
        "        LSTM(64, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='huber',\n",
        "        metrics=['mae', 'mse']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def train_model(model, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Enhanced training function\"\"\"\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=5,\n",
        "            min_lr=0.0001\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=10,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history\n",
        "\n",
        "def analyze_feature_importance(model, X, y_test, feature_names):\n",
        "    \"\"\"Analyze feature importance using permutation importance\"\"\"\n",
        "    base_mae = model.evaluate(X, y_test, verbose=0)[1]\n",
        "    importance = []\n",
        "\n",
        "    for i in range(X.shape[2]):\n",
        "        X_temp = X.copy()\n",
        "        X_temp[:, :, i] = np.random.permutation(X_temp[:, :, i])\n",
        "        new_mae = model.evaluate(X_temp, y_test, verbose=0)[1]\n",
        "        importance.append((feature_names[i], new_mae - base_mae))\n",
        "\n",
        "    importance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    features, scores = zip(*importance[:10])  # Top 10 features\n",
        "    plt.bar(features, scores)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('Top 10 Most Important Features')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wgkxeYMu8HSD",
        "outputId": "ac064202-c15d-4e7b-ca00-e2e5df88f26c"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "def main():\n",
        "    # Print runtime information\n",
        "    current_datetime = \"2025-02-17 18:17:03\"\n",
        "    current_user = \"sesiii\"\n",
        "\n",
        "    # Load demand data\n",
        "    demand_df = pd.read_csv('data/electricity_demand/demand.csv')\n",
        "    demand_df['datetime'] = pd.to_datetime(demand_df['datetime'])\n",
        "    demand_df.set_index('datetime', inplace=True)\n",
        "    print(\"Demand data shape:\", demand_df.shape)\n",
        "\n",
        "    # Load weather data from all cities\n",
        "    weather_df = load_and_preprocess_weather_data()\n",
        "    print(\"Weather data shape:\", weather_df.shape)\n",
        "\n",
        "    # Prepare data\n",
        "    X, y, scaler, feature_names = prepare_data(demand_df, weather_df)\n",
        "\n",
        "    # Print data shapes and check for NaN values\n",
        "    print(\"\\nFinal Data Shapes:\")\n",
        "    print(\"X shape:\", X.shape)\n",
        "    print(\"y shape:\", y.shape)\n",
        "    print(\"NaN in X:\", np.isnan(X).any())\n",
        "    print(\"NaN in y:\", np.isnan(y).any())\n",
        "\n",
        "    # Split data\n",
        "    train_size = int(len(X) * 0.8)\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    # Further split training data for validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create and train model\n",
        "    model = create_model((X.shape[1], X.shape[2]))\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Train model\n",
        "    history = train_model(model, X_train, y_train, X_val, y_val)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions and actual values\n",
        "    pred_data = np.zeros((len(y_pred), len(feature_names)))\n",
        "    pred_data[:, 0] = y_pred.flatten()\n",
        "    y_pred_inv = scaler.inverse_transform(pred_data)[:, 0]\n",
        "\n",
        "    test_data = np.zeros((len(y_test), len(feature_names)))\n",
        "    test_data[:, 0] = y_test\n",
        "    y_test_inv = scaler.inverse_transform(test_data)[:, 0]\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = np.mean((y_pred_inv - y_test_inv) ** 2)\n",
        "    mae = np.mean(np.abs(y_pred_inv - y_test_inv))\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_test_inv - y_pred_inv) / y_test_inv)) * 100\n",
        "\n",
        "    # Print detailed metrics\n",
        "    print(\"\\nDetailed Metrics:\")\n",
        "    print(f\"Mean Squared Error: {mse:.2f} kW²\")\n",
        "    print(f\"Mean Absolute Error: {mae:.2f} kW\")\n",
        "    print(f\"Root Mean Squared Error: {rmse:.2f} kW\")\n",
        "    print(f\"Mean Absolute Percentage Error: {mape:.2f}%\")\n",
        "\n",
        "    # Plot results with confidence intervals\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    pred_std = np.std(y_pred_inv - y_test_inv)\n",
        "    plt.fill_between(\n",
        "        range(100),\n",
        "        y_pred_inv[:100] - 1.96 * pred_std,\n",
        "        y_pred_inv[:100] + 1.96 * pred_std,\n",
        "        alpha=0.2,\n",
        "        color='blue',\n",
        "        label='95% Confidence Interval'\n",
        "    )\n",
        "\n",
        "    # Save results and model\n",
        "    results = {\n",
        "        \"runtime_info\": {\n",
        "            \"datetime\": current_datetime,\n",
        "            \"user\": current_user\n",
        "        },\n",
        "        \"model_history\": history.history,\n",
        "        \"predictions\": y_pred_inv,\n",
        "        \"actual_values\": y_test_inv,\n",
        "        \"metrics\": {\n",
        "            \"mse\": mse,\n",
        "            \"mae\": mae,\n",
        "            \"rmse\": rmse,\n",
        "            \"mape\": mape\n",
        "        },\n",
        "        \"feature_names\": feature_names.tolist()\n",
        "    }\n",
        "\n",
        "    # Save results to pickle file\n",
        "    with open('forecast_results.pkl', 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "\n",
        "    # Save model in .keras format\n",
        "    model.save('electricity_demand_model.keras')\n",
        "\n",
        "    # Download files if in Colab environment\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download('forecast_results.pkl')\n",
        "        files.download('electricity_demand_model.keras')\n",
        "        print(\"\\nFiles downloaded successfully!\")\n",
        "    except:\n",
        "        print(\"\\nFiles saved locally (not running in Colab)\")\n",
        "\n",
        "    plt.plot(y_test_inv[:100], label='Actual', color='blue', alpha=0.7)\n",
        "    plt.plot(y_pred_inv[:100], label='Predicted', color='red', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.title('Electricity Demand Forecasting Results with Confidence Intervals')\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('Demand (kW)')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss', color='blue', alpha=0.7)\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', color='red', alpha=0.7)\n",
        "    plt.title('Model Loss During Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Analyze feature importance\n",
        "    analyze_feature_importance(model, X_test, y_test, feature_names)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ3qVPDV8Mt1"
      },
      "source": [
        "## Evaluation of Forecasting Performance\n",
        "\n",
        "### Selected Metrics:\n",
        "1. **Mean Absolute Error (MAE)**\n",
        "   - Directly interpretable in the same units as demand\n",
        "   - Less sensitive to outliers than MSE\n",
        "\n",
        "2. **Root Mean Square Error (RMSE)**\n",
        "   - Penalizes larger errors more heavily\n",
        "   - Useful for comparing different models\n",
        "\n",
        "3. **Mean Absolute Percentage Error (MAPE)**\n",
        "   - Provides relative error measurement\n",
        "   - Easy to communicate to non-technical stakeholders\n",
        "\n",
        "## Error Analysis and Model Challenges\n",
        "\n",
        "### Identified Issues:\n",
        "1. **Data Quality**:\n",
        "   - Missing values in weather data\n",
        "   - Potential noise in measurements\n",
        "\n",
        "2. **Model Limitations**:\n",
        "   - Limited forecast horizon (24 hours)\n",
        "   - Sensitivity to sudden weather changes\n",
        "   - Computational resource requirements\n",
        "\n",
        "## Hypotheses for Accuracy Improvement\n",
        "\n",
        "1. **Feature Engineering**:\n",
        "   - Include holiday indicators\n",
        "   - Add lagged demand values\n",
        "   - Create interaction features between temperature and time\n",
        "\n",
        "2. **Model Enhancements**:\n",
        "   - Implement attention mechanism\n",
        "   - Use ensemble methods\n",
        "   - Increase model capacity\n",
        "\n",
        "## Expected Benefits of Model Deployment\n",
        "\n",
        "1. **Operational Efficiency**:\n",
        "   - Better resource allocation\n",
        "   - Reduced energy waste\n",
        "   - Improved grid stability\n",
        "\n",
        "2. **Cost Savings**:\n",
        "   - Optimized power generation\n",
        "   - Reduced peak demand charges\n",
        "   - Better maintenance scheduling\n",
        "\n",
        "3. **Environmental Impact**:\n",
        "   - Lower carbon emissions\n",
        "   - More efficient renewable energy integration"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "your_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
